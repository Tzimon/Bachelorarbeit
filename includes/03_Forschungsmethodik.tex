\chapter{Objective specification and presentation of the research methodology}

Having laid the groundwork with essential concepts necessary for this thesis,
this chapter aims to outline the objectives of the practical segment as well as the research methodology employed to achieve them.
In the first part, the specific objectives are defined. 
Afterward, in the second part the used research framework \ac{DSR} and the two research methods Prototyping and Simulation are explained.

\section{Objective specification}
The objective of this thesis is to develop a Simulator Pipeline that facilitates the exploration of both the implementation and performance of \ac{BM}s on a \ac{mem-HNN}.
In the beginning, the \ac{IT}-artifact to be implemented is modeled and all components, transitions and processes of the overall solution are identified.
This tool is then used to obtain comparable values in terms of energy consumption and computing speed for a typical workload, relative to Metropolis-Hastings.
Previous research has already shown that Ising machines and \ac{mem-HNN}s are capable of implementing \ac{BM}s.
However, these were proof-of-concepts as mentioned in 2.4.4, where no complete accelerator system was used.
Therefore, no clear statements were possible regarding the actual speed and energy consumption of an accelerator that would allow a comparison with digital computers.
Hence, to answer the primary research questions of this thesis, an \ac{IT}-artifact in the form of a Simulator Pipeline is implemented.
This artifact allows to study of training and inference of \ac{BM}s, where the statistical sampling of activation probabilities is performed with a hardware simulator of the \ac{mem-HNN}.
This hardware simulation contains a behavioral model of the different hardware components of a \ac{mem-HNN} described in 2.4.
To provide insights, key performance metrics for the simulation are identified in the literature: throughput (samples/second) and energy consumption (energy/operation).\footnote{cf.\cite{caiPowerefficientCombinatorialOptimization2020}, p. 409-418; cf.\cite{ortega-zamoranoFPGAHardwareAcceleration2016}, p. 16-17; cf.\cite{aaditAcceleratingAdaptiveParallel2023}, p. 2; cf.\cite{bellettiJanusFPGABasedSystem2009}, p. 55}

Moreover, to allow an intrinsic verification and comparison against conventional sampling methods, the software artifact also includes Gibbs Sampling and Metropolis-Hastings sampling methods.
With the software artifact, an exemplary machine learning workload is analyzed and simulated performance metrics are derived.
This analysis includes the optimization of the \ac{mem-HNN}s hyperparameters as well the different update methods discussed in 2.4.
Then, the performance metrics are intrinsically compared against conventional sampling methods to understand the potential of \ac{mem-HNN}s for sampling and machine learning applications.
By benchmarking these aspects against the conventional methods, this thesis aims to underscore the potential of the \ac{mem-HNN} in practical training of \ac{RBM}s.
Building upon the foundational work, this research also explores the implementation of the N/2 synchronous update mechanism, which anticipates higher sampling speeds and efficiency.

\ac{DSR} is used as a research framework to iteratively create and employ the \ac{IT}-artifact to answer the thesis's research question. 
During the different design iterations, the software artifact is developed using rapid prototyping for the implementation of the \ac{RBM} on the simulated \ac{mem-HNN}.
The last iteration uses a simulation as a research method because the behavior and performance of the system are measured and the underlying model is already finished with the last prototyping iteration. 
Since the practical functionality still requires validation, the \ac{DSR} process,
combined with prototyping and followed by simulation if successful, introduces flexibility and a problem-oriented structure that are crucial for this new method.

\section{Design Science Research}

\ac{DSR} is a core research method within the field of business informatics that ``creates and evaluates \ac{IT}-artifacts intended to solve identified organizational problems''.\footcite[77]{hevnerDesignScienceInformation2004a}
A systematic \ac{DSR} process established by Henver et al. lays a solid groundwork for conducting the research with rigor, offering a degree of confidence that the endeavor will yield meaningful outcomes.\footnote{cf.\cite{baskervilleDesignScienceResearch2018}, p. 368; cf.\cite{hevnerDesignScienceInformation2004a}, p. 77}
Artifacts in \ac{DSR} can be constructs, models, methods or instantiations.\footcite[77]{hevnerDesignScienceInformation2004a}
In addition to that, Gregor and Hevner (2013) categorize the underlying \ac{IT}-artifact based on their abstraction level and maturities.
Hence, level 1 represents a specific, limited and less mature implementation of an artifact, level 2 is operational principles or architecture like constructs, methods or models, while level 3 represents a well-developed midrange design theory.\footcite[cf.][342]{gregorPositioningPresentingDesign2013}
The development of the artifact is performed incrementally with specific goals for each iteration, which is beneficial for \ac{IT}-artifacts that can be adjusted after every iteration.\footcite[cf.][343]{gregorPositioningPresentingDesign2013}

Henver et al. also introduced 7 guidelines that still today serve as a framework for different \ac{DSR} approaches.
Arguably, the most important two guidelines are, that the research must create a viable artifact that in the next step is able to solve the organizational problem. 
Another important guideline is that the artifact needs to be rigorously evaluated in utility, quality and efficiency.\footcite[83]{hevnerDesignScienceInformation2004a}
Thereupon Peffer et al. introduced a well-known \ac{DSR} Process Model, which has 6 different phases: Identify problem \& Motivate, Define Objectives of a solution, 
Design \& Development, Demonstration, Evaluation and Communication.\footcite[cf.][54]{peffersDesignScienceResearch2007a}
Another interesting approach by Österle et. al is called design-oriented business informatics. 
This \ac{DSR} method is used in this thesis for the following reasons.
His approach compresses the phases of Peffer et al. into a more compact model and also gives a more detailed explanation of each phase while still complying with the guidelines established by Henver et al..\footcite[cf.][1-6]{oesterleMemorandumZurGestaltungsorientierten2010}
On top of this promising framework, they created a \ac{DSR} model called consortial research.
It addresses problems for collaborative research in terms of access to practical knowledge, rapid change and practical orientation and a lack of support for knowledge transfer.\footcite[cf.][273-274]{oesterleKonsortialforschung2010}
Österle et al. aims to bridge the gap between the knowledge base of both science and practice, with a focus on evaluating and ensuring the reproducibility of research outcomes.\footcite[cf.][5]{oesterleMemorandumZurGestaltungsorientierten2010}
However, the individual phases of the research framework can also be implemented on their own and the best features 
of the research framework especially the contents of the phases should be combined with its older framework of design-oriented business informatics.
As shown in figure \ref{DSR_Modell} following model is used:
\begin{figure}[H]
    \centering
    \includegraphics[width=0.9\linewidth]{graphics/DSR_Modell.png}
    \caption{DSR model by Österle et. al\protect\footnotemark}
    \label{DSR_Modell}
\end{figure}
\footnotetext{inspired from \cite[cf.][278]{oesterleKonsortialforschung2010}}
This model uses an iterative process for the phases that allow backward steps to redo an already completed phase if requirements were not satisfied to an appropriate level.
The four phases ideally contain the following contents:

\textbf{Analysis:} This phase identifies and describes the motivation in practice and formulates the desired research objectives.
In addition to that, a vague research plan is introduced which can hold the goals of the project but also underlying constraints. 
Components of the research plan could be external stakeholders, funding, a timetable and of course a concept of the solution.
If possible also a research method should be selected.\footcite[cf.][4]{oesterleMemorandumZurGestaltungsorientierten2010}

\textbf{Design:} The \ac{IT}-artifact is designed and developed with regard to the selected research methodology. 
Specific processes must be justified and comprehensible with consideration of the outcomes of the analysis phase.
The Design process can take multiple iterations on its own with the chance of making adjustments until the requirements are fulfilled.
The outcomes is a functional \ac{IT}-artifact that fulfills the set goals.\footcite[cf.][279]{oesterleKonsortialforschung2010}

\textbf{Evaluation:} Here the established \ac{IT}-artifact needs to be validated against the earlier specified goals. 
Furthermore, it can be validated against the chosen research method. 
This means they must be applicable and they must provide the expected benefit.
If the artifact can not be tested with, for example, a pilot application, it is possible to pursue expert interviews to validate the outcome.\footcite[cf.][279]{oesterleKonsortialforschung2010}

\textbf{Diffusion:} In this phase the results are generally made available to the public.
Therefore, the results need to be prepared for publication in individual communities.
Methods for publication could be teaching at universities and colleges and through their publication in books and specialist journals.
Diffusion in practice also includes the implementation in companies and public administration which the solution was initially developed for.\footcite[cf.][5]{oesterleMemorandumZurGestaltungsorientierten2010}

\section{Prototyping}

Given that the aim of the implementation is to create a new \ac{IT}-artifact with a focus on rapid development, prototyping has been selected as the methodology.
Generally, prototyping is a fundamental practice in designing tools, applications or user interfaces and defining requirements within the framework of agile software development.
It belongs to the agile requirements engineering practice and allows to gather feedback on requirements in a light-weight fashion.\footcite[cf.][1]{bjarnasonModelSoftwarePrototyping2021a}
Prototypes are created to assist in the analysis and design of proposed systems.
A prototype can be defined as ``a simplified model of a proposed system, that is built for a specific purpose'', which can apply to various kind of systems like software, hardware or even people.\footcite[][470]{luqiRapidSoftwarePrototyping1992}
It can be seen as an early increment, model, or release that implements some features of the desired product or model and therefore represents it. 

At the core of prototyping, it comes down to the exploration of the solution space through experimenting with ideas,
collecting feedback and
communicating product requirements in an iterative detailing process.
Hence, prototyping can deliver new requirements that are elicited through exploration and can later be validated 
by testing technical feasibility or business viability.\footcite[cf.][8]{bjarnasonModelSoftwarePrototyping2021a}
A few benefits of prototyping are early construction with low development costs and no large upfront investments of either time or money.
In addition to that, it can promote innovation due to early results that can be communicated and if viable researched further.\footcite[cf.][25]{nelsonSoftwarePrototyping2016}
The reason to choose prototyping can have various reasons. 
This thesis uses this method for the design phase within \ac{DSR} due to the just-named benefits and the possibility of fast results and testing feasibility of the model.

Specifically, G. Arthur Mihram's prototyping model is chosen because it suits well the \ac{DSR} framework and overlaps with it. 
There are five steps to Mihram's prototyping process.
The first step, setting the ``modelling goals'' is already completed with the analysis phase of the \ac{DSR}.\footcite[cf.][71]{mihramSimulationMethodology1976}
Within each iteration in the design phase, a subselection of the goals is chosen to be prototyped. 
Furthermore, the previously established prototype is used as the basis for the following iteration phase allowing to implement more and more features.
In a second step ``systemic analysis'', the prototype can be categorized to set the prototypes behavioural mechanisms.\footcite[cf.][71-72]{mihramSimulationMethodology1976}
As a guideline to categorize this behaviour, the thesis uses the House of Prototyping Guidelines by Ahmed and Demirel.
These guidelines shown in \ref{attachement:prototyping_dimensions} introduce five different dimensions used to categorize prototypes:
Type of Prototype(1), Fidelity Level(2), Complexity(3), Scale(4) and Number of Iterations(5).\footcite[cf.][6-7]{ahmedPrototypingFrameworkHumanCentered2021}

The third step ``model synthesis'' requires a description and a chronological sequences of the prcoesses.\footcite[cf.][71-72]{mihramSimulationMethodology1976}
Furthermore, this is the phase of exploration and ends when the complete set of entities and the environment have been developed in a computer-directed language and the data is provided in machine-readable formats.\footcite[cf.][75-76]{mihramSimulationMethodology1976}

The last steps of Mihram's model: ``model confirmation'' and ``scientific interference'' are not considered since they overlap with the \ac{DSR} phases of evaluation and diffusion. 
This simply prevents a duplication of work.
Therefore, the categorization of the prototype and afterwards the ``model synthesis'' is executed per iteration in the prototyping model used in this thesis. 

\section{Simulation}

Simulation has been chosen as the methodology for the evaluation phase of the \ac{DSR} framework to collect data.
This is necessary because the \ac{mem-HNN} is still under development and actual devices with the functionality required for the implementation for \ac{BM}s are not yet available.
In these development phases of hardware devices, it is therefore common to use simulation tools, that allow fast and accurate predictions of performance long before actual measurements on a device are possible.
A simulation model can be defined as a computerized representation of a given model capturing its dynamic behavior.
The primary motivation for establishing a simulation model or using any other modeling method like prototyping is that it is
a cheap and fast way to gain important insights without being exposed to the following constraints: costs, risks or logistics of manipulating the real system.\footcite[cf.][92]{kellnerSoftwareProcessSimulation1999}
A single \ac{ASIC} chip has a long development time due to the complex layout and fabrication process and can cost between 10.000 to 100.000 USD.
Furthermore, the gathered data helps with decision-making at strategic and operational levels.\footcite[cf.][93]{kellnerSoftwareProcessSimulation1999}
For example, with the results of a simulation, it can be decided if the new hardware works like expected and can be set up for production.
These are the reasons why the simulation methodology is chosen for the evaluation phase of the prototype. 

Computer simulation involves adjusting a computer-based model to better analyze how a system behaves and to evaluate approaches for their operation, either for descriptive or predictive purposes.\footcite[cf.][13-14]{abarAgentBasedModelling2017}
In the case of the \ac{mem-HNN}, there is a need for the evaluation of software performance in combination with the hardware to gather proper data.
The reason for this is that only using a functional software simulation without considering the hardware specifications results in a decreased price and time but with a significant precision loss.\footcite[cf.][470-471]{sarhadiStateArtHardware2015}
However, precision and efficiency are a key part of being able to answer the research question.

A general simulation model published by Kellner/Madachy/Raffo can be seen as an overview of the work in the simulation field.
It consists of the following entities: (0) model purpose, (1) model scope, (2) result variables, (3) process abstraction and (4) input parameters.  

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\linewidth]{graphics/Simulation_Modell.png}
    \caption{general simulation model\protect\footnotemark}
    \label{simulation_Modell}
\end{figure}
\footnotetext{\cite[][95]{kellnerSoftwareProcessSimulation1999}}

The general \textbf{model purpose} is based on the specific research question that needs to be answered.
It is crucial to thoroughly understand the effects based on this key question to ensure the correct selection of the \textbf{model scope}.\footcite[cf.][95]{kellnerSoftwareProcessSimulation1999}
This can be an iterative process that includes the selection of a scope, for example, a development project, long-term product evolution etc. and within 
this scope, an estimated timespan (short(less than 12 months), medium (12-24 months), long (more than 24 months)) needs to be selected. 
In addition to that, the organizational simulation width is set (less than one project team, one project team, multiple project teams).\footcite[cf.][96]{kellnerSoftwareProcessSimulation1999}

The \textbf{result variables} are information elements that are the central key entity of the simulation model. 
They change based on the main question being asked, representing the crucial signs of a successful simulation.
Typical metrics for software simulation could be: effort/cost, throughput/productivity, queue lengths in the backlog,
energy efficiency, return on investment.
Furthermore, with one simulation multiple result variables can be gathered simultanously.\footcite[cf.][96-97]{kellnerSoftwareProcessSimulation1999}

\textbf{Process abstraction} includes the inner structure of the simulation model.
Therefore, all the processes, vital resources, dependencies and iteration loops need to be considered to achieve the desired result variables and to answer the key quesions.\footcite[cf.][97]{kellnerSoftwareProcessSimulation1999}
Lastly, the \textbf{input parameters} consider all the parameters that are needed to produce viable outcomes. 
This can range up to hundreds of data parameters to achieve the desired results. 
In theory, these parameters can also be extended to human resources like software engineers who are needed for their skills in programming knowledge.\footcite[cf.][97-98]{kellnerSoftwareProcessSimulation1999}

This general usable simulation model is not only part of the \ac{DSR} evaluation phase but also part of the \ac{ASIC} design process. 
Therefore, the model is modified to match the needs for a performance simulation of the \ac{mem-HNN}.
The simulation model is part of the architecture and high-level design of the \ac{ASIC} design process.
It involves selecting key components like processors, memory blocks, and communication interfaces and carrying out a functional verification through a suitable simulation.\footnote{cf.\cite{raoUltimateGuideASIC}, p. 1; cf.\cite{ASICDesignFlow}, p. 1}
The modification to the model is expressed through the actual energy model of the \ac{mem-HNN}, which is added to the simulation model, that can compute energy usage per clock cycle. 
Hence, depending on a specific input it can calculate how much energy was required to do computations that are the output and used for the next cycle. 
