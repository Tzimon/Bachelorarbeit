\chapter*{Appendix}
\addcontentsline{toc}{chapter}{Appendix}
\section*{List of appendices}
\vspace{-8em}

% vor \listofanhang müssen Einrückungen angepasst werden
\abstaendeanhangverzeichnis

\listofanhang
\clearpage
\spezialkopfzeile{Attachment} % damit in der Kopfzeile das Wort "Anhang" angezeigt wird

\lstset{language=TeX, % hervorzuhebende Keywords definieren
  morekeywords={anhang, anhangteil}
}

\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3,
  morecomment=[l]{\#} % This line tells 'listings' that '#' introduces a single-line comment
}

\anhang{House of Prototyping Guidelines: Prototyping Dimensions}\label{attachement:prototyping_dimensions}
\begin{figure}[htb]
\centering
\includegraphics[width=0.9\linewidth]{graphics/Prototyping_dimensions.png}
\caption{Prototyping Dimensions to categorize prototypes}
\end{figure}

\anhang{Weight matrix within the Hopfield Network}\label{attachement:weight_matrix}
\begin{lstlisting}
def initialize_weights_and_biases(self, components):
  num_hidden = self.num_hidden_neurons
  num_visible = self.num_visible_neurons

  #Result size: 100,64

  # Initialize a symmetric weight matrix for simplicity
  self.weights = np.zeros((num_hidden + num_visible, num_hidden + num_visible))

  # Fill in the weights from components for connections between hidden and visible layers
  # for connections between hidden and visible layers
  for i in range(num_hidden):  # Looping through hidden neurons
      for j in range(num_visible):  # Looping through visible neurons
          hidden_index = i
          visible_index = j + num_hidden

          # Additional safeguard: Ensure 'j' is within the bounds of 'components' second dimension
          if j < len(components[0]):
              self.weights[hidden_index, visible_index] = components[i][j]
              self.weights[visible_index, hidden_index] = components[i][j]
          else:
              print(f"Attempted to access components[{i}][{j}], which is out of bounds.")

  return self.weights
\end{lstlisting}

\anhang{Autocorrelation function within the prototype}\label{attachement:autocorrelation}
\begin{lstlisting}
def autocorr(self, x):
        # print("das ist das shape:", x.shape)
        # print("das ist das shape:", x.shape[1])
        average = 60
        leng= 8999-average
        autocorr = np.zeros(leng)
        
        for i in range(0, leng):
            for k in range (0, average):
                autocorr[i] += np.dot(x[:, k]-np.mean(x[:,k]), x[:, k+i]-np.mean(x[:,k+1])) 

        return autocorr / autocorr[0]
\end{lstlisting}

\anhang{Autocorrelation for all sampling methods with outliers}\label{attachement:autocorrelation_errors}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.9\linewidth]{graphics/Visualisierungen_Autocorr_individual_8.png}
  \caption{Autocorrelation for the three sampling methods with outliers}
\end{figure}

\anhang{Throughput with outliers for all sampling methods}\label{attachement:throughput_errors}
\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\linewidth]{graphics/Visualisierungen_throughput_log_3.png}
  \caption{Throughput with outliers}
\end{figure}